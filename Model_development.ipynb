{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a82e66a-60af-43fa-9270-0e348dab55f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loading data...\n",
      "Initializing model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████████████████████████████████████████████████████| 500/500 [32:49<00:00,  3.94s/it, loss=0.24]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "Avg training loss: 40.10%\n",
      "Validation accuracy: 86.70%\n",
      "Final model accuracy: 86.7 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/29 01:26:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating performance degradation...\n",
      "Email alert sent!\n",
      "Performance drop detected! Retraining...\n",
      "Time to retrain this bad boy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████████████████████████████████████████████████████| 500/500 [33:01<00:00,  3.96s/it, loss=0.47]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "Avg training loss: 23.62%\n",
      "Validation accuracy: 87.30%\n",
      "Retrained model accuracy: 87.3 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/29 02:04:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model retrained. New accuracy: 87.3 %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import mlflow\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from flask import Flask, request, jsonify\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Let's see if we can use GPU.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load data function\n",
    "def load_data(file_path, sample_size=None):\n",
    "    df = pd.read_csv(file_path)\n",
    "    if sample_size:\n",
    "        return df.sample(n=sample_size, random_state=42)\n",
    "    return df\n",
    "\n",
    "# Tokenize function\n",
    "def tokenize_data(texts, tokenizer, max_length=128):\n",
    "    return tokenizer(texts, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
    "\n",
    "# Train function\n",
    "def train_model(model, train_dataloader, val_dataloader, epochs=3, lr=2e-5):\n",
    "    optimizer = AdamW(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "        \n",
    "        for batch in progress_bar:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch[0].to(device)\n",
    "            attention_mask = batch[1].to(device)\n",
    "            labels = batch[2].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({\"loss\": loss.item()})\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_dataloader)\n",
    "        val_accuracy = evaluate_model(model, val_dataloader)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        print(f\"Avg training loss: {avg_train_loss*100:.2f}%\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        \n",
    "        # Log metrics with MLflow\n",
    "        mlflow.log_metric(\"train_loss\", avg_train_loss, step=epoch)\n",
    "        mlflow.log_metric(\"val_accuracy\", val_accuracy, step=epoch)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Evaluate function\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actual_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch[0].to(device)\n",
    "            attention_mask = batch[1].to(device)\n",
    "            labels = batch[2].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            _, preds = torch.max(outputs.logits, dim=1)\n",
    "            \n",
    "            predictions.extend(preds.cpu().tolist())\n",
    "            actual_labels.extend(labels.cpu().tolist())\n",
    "    \n",
    "    return accuracy_score(actual_labels, predictions)\n",
    "\n",
    "# Monitor performance function\n",
    "def monitor_performance(current_accuracy, threshold=0.85):\n",
    "    if current_accuracy < threshold:\n",
    "        send_email_alert(f\"Model performance has degraded. Current accuracy: {current_accuracy * 100:.2f}%\")\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Email alert function\n",
    "def send_email_alert(message):\n",
    "    # Note to self: Remember to use environment variables for these!\n",
    "    sender_email = \"rupeshs2103@gmail.com\"\n",
    "    receiver_email = \"rupesh2103033@gmail.com\"\n",
    "    password = \"bqviuuaefhfmrycc\"\n",
    "    \n",
    "    msg = MIMEMultipart()\n",
    "    msg['From'] = sender_email\n",
    "    msg['To'] = receiver_email\n",
    "    msg['Subject'] = \"Model Performance Alert\"\n",
    "    \n",
    "    msg.attach(MIMEText(message, 'plain'))\n",
    "    \n",
    "    try:\n",
    "        with smtplib.SMTP('smtp.gmail.com', 587) as server:\n",
    "            server.starttls()\n",
    "            server.login(sender_email, password)\n",
    "            server.send_message(msg)\n",
    "        print(\"Email alert sent!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Oops! Couldn't send email: {e}\")\n",
    "\n",
    "# Retrain function\n",
    "def retrain_model(model, train_dataloader, val_dataloader, epochs=1):\n",
    "    print(\"Time to retrain this bad boy...\")\n",
    "    mlflow.end_run()\n",
    "    with mlflow.start_run():\n",
    "        model = train_model(model, train_dataloader, val_dataloader, epochs=epochs)\n",
    "        retrained_accuracy = evaluate_model(model, val_dataloader)\n",
    "        print(\"Retrained model accuracy:\", retrained_accuracy*100,\"%\")\n",
    "        mlflow.log_metric(\"retrained_accuracy\", retrained_accuracy)\n",
    "        mlflow.pytorch.log_model(model, \"retrained_model\")\n",
    "        torch.save(model.state_dict(), \"text_classification_model_retrained.pth\")\n",
    "    return retrained_accuracy\n",
    "\n",
    "# Batch inference function\n",
    "def batch_inference(input_file, output_file, batch_size=32):\n",
    "    df = pd.read_csv(input_file)\n",
    "    texts = df['review'].tolist()\n",
    "    predictions = []\n",
    "    \n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        inputs = tokenizer(batch_texts, return_tensors=\"pt\", truncation=True, padding=True, max_length=128).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        probabilities = torch.softmax(outputs.logits, dim=1)\n",
    "        batch_predictions = torch.argmax(probabilities, dim=1).tolist()\n",
    "        predictions.extend(batch_predictions)\n",
    "    \n",
    "    df['prediction'] = ['positive' if p == 1 else 'negative' for p in predictions]\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Batch predictions saved to {output_file}\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Start MLflow run\n",
    "    with mlflow.start_run():\n",
    "        # Load and preprocess data\n",
    "        print(\"Loading data...\")\n",
    "        data = load_data(\"C:\\\\Users\\\\rupes\\\\Desktop\\\\Problem_1_Rupesh\\\\Data\\\\IMDB Dataset.csv\", sample_size=10000)\n",
    "        texts = data['review'].tolist()\n",
    "        labels = (data['sentiment'] == 'positive').astype(int).tolist()\n",
    "        \n",
    "        # Split the data\n",
    "        train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Initialize tokenizer and model\n",
    "        print(\"Initializing model...\")\n",
    "        tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "        model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2).to(device)\n",
    "        \n",
    "        # Tokenize and encode the data\n",
    "        train_encodings = tokenize_data(train_texts, tokenizer)\n",
    "        val_encodings = tokenize_data(val_texts, tokenizer)\n",
    "        \n",
    "        # Create DataLoaders\n",
    "        train_dataset = TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], torch.tensor(train_labels))\n",
    "        val_dataset = TensorDataset(val_encodings['input_ids'], val_encodings['attention_mask'], torch.tensor(val_labels))\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "        val_dataloader = DataLoader(val_dataset, batch_size=16)\n",
    "        \n",
    "        # Train the model\n",
    "        print(\"Training model...\")\n",
    "        model = train_model(model, train_dataloader, val_dataloader, epochs=1)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        final_accuracy = evaluate_model(model, val_dataloader)\n",
    "        print(\"Final model accuracy:\", final_accuracy*100,\"%\")\n",
    "        \n",
    "        # Log final metrics and model\n",
    "        mlflow.log_metric(\"final_accuracy\", final_accuracy)\n",
    "        mlflow.pytorch.log_model(model, \"model\")\n",
    "        \n",
    "        # Save the model\n",
    "        torch.save(model.state_dict(), \"text_classification_model.pth\")\n",
    "        \n",
    "        # Simulate performance degradation\n",
    "        time.sleep(5)\n",
    "        print(\"Simulating performance degradation...\")\n",
    "        degraded_accuracy = 0.80\n",
    "        if monitor_performance(degraded_accuracy):\n",
    "            print(\"Performance drop detected! Retraining...\")\n",
    "            new_accuracy = retrain_model(model, train_dataloader, val_dataloader)\n",
    "            print(\"Model retrained. New accuracy:\", new_accuracy*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73fff46d-9716-495b-8128-372946e5f1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Flask app for live inference...\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, render_template_string\n",
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Initialize model and tokenizer\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "#HTML template\n",
    "HTML_TEMPLATE = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Sentiment Analysis</title>\n",
    "    <style>\n",
    "        body {\n",
    "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "            display: flex;\n",
    "            justify-content: center;\n",
    "            align-items: center;\n",
    "            height: 100vh;\n",
    "            margin: 0;\n",
    "            background: linear-gradient(135deg, #ece9e6, #ffffff);\n",
    "        }\n",
    "        .container {\n",
    "            text-align: center;\n",
    "            padding: 30px;\n",
    "            background-color: #ffffff;\n",
    "            border-radius: 10px;\n",
    "            box-shadow: 0 10px 20px rgba(0, 0, 0, 0.15);\n",
    "            max-width: 550px;\n",
    "            width: 95%;\n",
    "            transition: transform 0.3s;\n",
    "        }\n",
    "        .container:hover {\n",
    "            transform: translateY(-5px);\n",
    "        }\n",
    "        h1 {\n",
    "            margin-bottom: 20px;\n",
    "            color: #333;\n",
    "        }\n",
    "        textarea {\n",
    "            width: 100%;\n",
    "            height: 150px;\n",
    "            padding: 12px;\n",
    "            border: 1px solid #ccc;\n",
    "            border-radius: 5px;\n",
    "            font-size: 14px;\n",
    "            resize: none;\n",
    "            margin-bottom: 15px;\n",
    "            transition: box-shadow 0.3s;\n",
    "        }\n",
    "        textarea:focus {\n",
    "            box-shadow: 0 0 10px rgba(0, 123, 255, 0.3);\n",
    "            border-color: #007bff;\n",
    "        }\n",
    "        button {\n",
    "            padding: 12px 25px;\n",
    "            border: none;\n",
    "            border-radius: 5px;\n",
    "            background-color: #007bff;\n",
    "            color: #ffffff;\n",
    "            font-size: 16px;\n",
    "            cursor: pointer;\n",
    "            transition: background-color 0.3s, box-shadow 0.3s;\n",
    "        }\n",
    "        button:hover {\n",
    "            background-color: #0056b3;\n",
    "            box-shadow: 0 4px 10px rgba(0, 91, 187, 0.3);\n",
    "        }\n",
    "        #result {\n",
    "            margin-top: 15px;\n",
    "            font-size: 16px;\n",
    "            color: #555;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"container\">\n",
    "        <h1>Sentiment Analysis</h1>\n",
    "        <form id=\"sentiment-form\">\n",
    "            <textarea id=\"text-input\" placeholder=\"Enter your text here...\"></textarea>\n",
    "            <br>\n",
    "            <button type=\"submit\">Analyze Sentiment</button>\n",
    "        </form>\n",
    "        <p id=\"result\"></p>\n",
    "    </div>\n",
    "\n",
    "    <script>\n",
    "        document.getElementById('sentiment-form').addEventListener('submit', function(e) {\n",
    "            e.preventDefault();\n",
    "            var text = document.getElementById('text-input').value.trim();\n",
    "            if (!text) {\n",
    "                document.getElementById('result').textContent = 'Please enter some text.';\n",
    "                return;\n",
    "            }\n",
    "            fetch('/predict', {\n",
    "                method: 'POST',\n",
    "                headers: {\n",
    "                    'Content-Type': 'application/json',\n",
    "                },\n",
    "                body: JSON.stringify({ text: text }),\n",
    "            })\n",
    "            .then(response => response.json())\n",
    "            .then(data => {\n",
    "                document.getElementById('result').textContent = 'Prediction: ' + data.prediction;\n",
    "            })\n",
    "            .catch(error => {\n",
    "                document.getElementById('result').textContent = 'Error analyzing sentiment.';\n",
    "                console.error('Error:', error);\n",
    "            });\n",
    "        });\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Route to serve the main page\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template_string(HTML_TEMPLATE)\n",
    "\n",
    "# Prediction route\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.get_json()\n",
    "    text = data.get('text', '')\n",
    "\n",
    "    # Tokenize and predict\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    prediction = torch.argmax(outputs.logits, dim=1).item()\n",
    "\n",
    "    # Map prediction to sentiment\n",
    "    sentiment = 'Positive' if prediction == 1 else 'Negative'\n",
    "    return jsonify({'prediction': sentiment})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"Starting Flask app for live inference...\")\n",
    "    app.run(debug=True, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941f419a-487e-447f-96f3-1e3358314161",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
